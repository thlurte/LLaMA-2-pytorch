<h2 align="center">LLaMA-02</h2>
<p align="center">pytorch implementation of H. Touvron  et al. (2023)</p>  
<br>

Llama 2[^1] is a decoder-only language model, which takes the input sentence as ordered tokens and predicts the next token.
<p align="center">
  <img src="/assets/pepper.png" alt="Transformer Network Architecture">
</p>


[^1]:H. Touvron _et al._, “Llama 2: Open Foundation and Fine-Tuned Chat Models.” arXiv, Jul. 19, 2023. Available: [http://arxiv.org/abs/2307.09288](http://arxiv.org/abs/2307.09288). [Accessed: Mar. 02, 2024]